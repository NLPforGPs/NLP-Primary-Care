cpu-bind=MASK - bp1-gpu003, task 4294967295 4294967295 [0]: mask 0x1010 set

CondaValueError: prefix already exists: /user/home/zu20361/.conda/envs/NLP_GP

[nltk_data] Downloading package wordnet to
[nltk_data]     /user/home/zu20361/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to
[nltk_data]     /user/home/zu20361/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-08 22:34:01,864 - /user/home/zu20361/NLP-Primary-Care/./run_plms.py[line:93] - INFO: training...
2021-12-08 22:34:01,865 - /user/home/zu20361/NLP-Primary-Care/./run_plms.py[line:101] - INFO: /user/work/zu20361/PCC/prepared/dl_data/desc/cks_only/multiclass/fine_grained_new_16cat not exists, generating data....
2021-12-08 22:34:03,838 - /user/home/zu20361/.conda/envs/NLP_GP/lib/python3.9/site-packages/datasets/builder.py[line:377] - WARNING: Using custom data configuration default-203e642b1c14b202
0 examples [00:00, ? examples/s]2021-12-08 22:34:04,011 - /user/home/zu20361/.cache/huggingface/modules/datasets_modules/datasets/description_dataset/d1e7e6de6d47305aa98cf02bede76588ca92ee8c617b143052c51e176d9c6484/description_dataset.py[line:65] - INFO: Generating examples...
                                0 examples [00:00, ? examples/s]2021-12-08 22:34:04,091 - /user/home/zu20361/.cache/huggingface/modules/datasets_modules/datasets/description_dataset/d1e7e6de6d47305aa98cf02bede76588ca92ee8c617b143052c51e176d9c6484/description_dataset.py[line:65] - INFO: Generating examples...
                                  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 795.66it/s]
2021-12-08 22:34:04,123 - /user/home/zu20361/NLP-Primary-Care/./run_plms.py[line:124] - INFO: using traditional bert classifier...
2021-12-08 22:34:04,127 - /user/home/zu20361/NLP-Primary-Care/./run_plms.py[line:134] - INFO: save label file to /user/work/zu20361/PCC/prepared/dl_data/fg_label2id_new_16cat.json
Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/4 [00:00<?, ?ba/s]100%|██████████| 4/4 [00:00<00:00, 304.60ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00, 253.77ba/s]
  0%|          | 0/4 [00:00<?, ?ba/s] 25%|██▌       | 1/4 [00:00<00:00,  3.38ba/s] 50%|█████     | 2/4 [00:00<00:00,  3.81ba/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.99ba/s]100%|██████████| 4/4 [00:00<00:00,  4.89ba/s]
  0%|          | 0/1 [00:00<?, ?ba/s]100%|██████████| 1/1 [00:00<00:00,  4.10ba/s]100%|██████████| 1/1 [00:00<00:00,  4.10ba/s]
  0%|          | 0/20 [00:00<?, ?it/s]2021-12-08 22:36:14,200 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 0/20, train_loss: 5.660477881479745, train_accuracy:0.025252525252525252
2021-12-08 22:36:30,121 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.12710084033613445, the dev_loss is 5.290400236594577, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
  5%|▌         | 1/20 [02:22<45:01, 142.18s/it]2021-12-08 22:38:37,057 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 1/20, train_loss: 4.526669243369439, train_accuracy:0.2588383838383838
2021-12-08 22:38:53,120 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.3880552220888355, the dev_loss is 3.70219592336847, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 10%|█         | 2/20 [04:45<42:47, 142.66s/it]2021-12-08 22:41:00,144 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 2/20, train_loss: 3.018963652126717, train_accuracy:0.49579124579124584
2021-12-08 22:41:16,161 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.5477190876350541, the dev_loss is 2.618139344103196, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 15%|█▌        | 3/20 [07:08<40:28, 142.83s/it]2021-12-08 22:43:23,196 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 3/20, train_loss: 2.0156406948361734, train_accuracy:0.6539351851851851
2021-12-08 22:43:39,219 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.6000900360144058, the dev_loss is 2.0203397589571335, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 20%|██        | 4/20 [09:31<38:06, 142.92s/it]2021-12-08 22:45:46,236 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 4/20, train_loss: 1.356623567565523, train_accuracy:0.7639941077441078
2021-12-08 22:46:02,248 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.6494597839135655, the dev_loss is 1.6795955831263245, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 25%|██▌       | 5/20 [11:54<35:44, 142.96s/it]2021-12-08 22:48:09,439 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 5/20, train_loss: 0.9105388152629438, train_accuracy:0.8429082491582492
2021-12-08 22:48:25,476 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.6884753901560624, the dev_loss is 1.4495767507733417, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 30%|███       | 6/20 [14:17<33:22, 143.05s/it]2021-12-08 22:50:32,600 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 6/20, train_loss: 0.6219914380573865, train_accuracy:0.8976220538720538
2021-12-08 22:50:48,627 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.6950780312124849, the dev_loss is 1.3341455540987623, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 35%|███▌      | 7/20 [16:40<31:00, 143.08s/it]2021-12-08 22:52:55,803 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 7/20, train_loss: 0.40194025818220896, train_accuracy:0.9384469696969697
2021-12-08 22:53:11,819 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.7309423769507803, the dev_loss is 1.2421652710988742, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 40%|████      | 8/20 [19:03<28:37, 143.12s/it]2021-12-08 22:55:19,122 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 8/20, train_loss: 0.27052990056461457, train_accuracy:0.9560185185185185
 45%|████▌     | 9/20 [21:23<26:03, 142.16s/it]2021-12-08 22:57:39,045 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 9/20, train_loss: 0.18557801114799774, train_accuracy:0.9668560606060606
2021-12-08 22:57:55,082 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.7361944777911165, the dev_loss is 1.1875840438326366, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 50%|█████     | 10/20 [23:47<23:44, 142.49s/it]2021-12-08 23:00:02,176 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 10/20, train_loss: 0.13543446156233926, train_accuracy:0.9741161616161617
 55%|█████▌    | 11/20 [26:06<21:15, 141.67s/it]2021-12-08 23:02:22,151 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 11/20, train_loss: 0.0923796789579545, train_accuracy:0.9797979797979798
2021-12-08 23:02:38,219 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.743547418967587, the dev_loss is 1.1928398068681234, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 60%|██████    | 12/20 [28:30<18:57, 142.17s/it]2021-12-08 23:04:45,341 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 12/20, train_loss: 0.07292280502786691, train_accuracy:0.9829545454545454
 65%|██████▌   | 13/20 [30:50<16:30, 141.48s/it]2021-12-08 23:07:05,491 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 13/20, train_loss: 0.058577032064821455, train_accuracy:0.983270202020202
2021-12-08 23:07:21,567 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:72] - INFO: the dev_acc is 0.7436974789915967, the dev_loss is 1.2402247603231369, save best model to /user/work/zu20361/PCC/models/conventional/fine_grained/fine-grained-conventional-20epochs-16catbest-val-acc-model
 70%|███████   | 14/20 [33:13<14:12, 142.08s/it]2021-12-08 23:09:28,713 - /user/home/zu20361/NLP-Primary-Care/nn_model/desc_classifier.py[line:65] - INFO: Epochs: 14/20, train_loss: 0.04703364322535844, train_accuracy:0.9870580808080808
 75%|███████▌  | 15/20 [35:33<11:47, 141.42s/it]slurmstepd: error: *** JOB 260431 ON bp1-gpu003 CANCELLED AT 2021-12-08T23:09:42 DUE TO TIME LIMIT ***
