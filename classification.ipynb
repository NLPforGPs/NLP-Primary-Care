{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bec071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "from matplotlib import pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef73e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# alternatively, you may override the variables in oneinamillion.resources.py\n",
    "os.environ['PCC_BASE_DIR'] = \"Z:/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918514bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from oneinamillion.resources import PCC_BASE_DIR\n",
    "print(f\"RDSF base directory located at {PCC_BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecac653-2d0a-4fcd-a20a-10adb23cb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oneinamillion.pc_consultation import PCConsultation\n",
    "\n",
    "parser = PCConsultation()  # the only class needed to obtain all PC consultation data-pairs\n",
    "orig_dataset = parser.get_pd()\n",
    "\n",
    "# orig_dataset.head()  # uncomment to inspect the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea4eb6-0bd9-43b8-98cc-c26caca9fa97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data preparation\n",
    "\n",
    "First split the orig_dataset into train and test set, then we need to\n",
    "pre-process the transcript data\n",
    "\n",
    "This includes, cleaning text, stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fb443-83b6-4e2d-a5d7-79b9b8c662fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.preprocessing.data import extract_icpc_categories\n",
    "from utils.transcripts import preprocess_transcripts, read_transcript\n",
    "\n",
    "orig_dataset['codes'] = orig_dataset['icpc_codes'].apply(extract_icpc_categories)\n",
    "orig_dataset['transcript__conversation_clean'] = orig_dataset['transcript__conversation'].apply(preprocess_transcripts)\n",
    "orig_dataset['transcript__conversation_both'] = orig_dataset['transcript__conversation_clean'].apply(\n",
    "    lambda t: read_transcript(t, return_format='concat'))\n",
    "orig_dataset['transcript__conversation_gp'] = orig_dataset['transcript__conversation_clean'].apply(\n",
    "    lambda t: read_transcript(t, show_gp=True, show_patient=False, return_format='concat'))\n",
    "orig_dataset['transcript__conversation_patient'] = orig_dataset['transcript__conversation_clean'].apply(\n",
    "    lambda t: read_transcript(t, show_gp=False, show_patient=True, return_format='concat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634643c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "orig_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1d000",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "orig_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca3cb5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "y = orig_dataset['codes']\n",
    "mult_lbl_enc = MultiLabelBinarizer()\n",
    "y_hot = mult_lbl_enc.fit_transform(y)\n",
    "print(f\"{len(mult_lbl_enc.classes_)} classification categories: {mult_lbl_enc.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71abd38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0f43b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "X = np.arange(orig_dataset['index'].shape[0]).reshape((-1, 1))\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y_hot, test_size=0.2)\n",
    "\n",
    "train_set = orig_dataset.iloc[X_train.flatten()]\n",
    "test_set = orig_dataset.iloc[X_test.flatten()]\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e8574",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ICPC descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d41a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from oneinamillion.clinical_codes.icpc import IcpcParser\n",
    "\n",
    "icpc_parser = IcpcParser()\n",
    "icpc_df = icpc_parser.get_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b2ce2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.preprocessing.text import utils_preprocess_text\n",
    "\n",
    "icpc_df['cat'] = icpc_df['Code'].astype('string').apply(lambda x: x[0].upper())\n",
    "\n",
    "clean_col = lambda x: utils_preprocess_text(x) if not pd.isna(x) else x\n",
    "# building keyword collection from three columns of the ICPC-2 descriptions\n",
    "icpc_df['criteria_prepared'] = icpc_df['criteria'].apply(clean_col)\n",
    "icpc_df['inclusion_prepared'] = icpc_df['inclusion'].apply(clean_col)\n",
    "icpc_df['preferred_prepared'] = icpc_df['preferred'].apply(clean_col)\n",
    "icpc_df['keywords'] = icpc_df[['preferred_prepared', 'criteria_prepared', 'inclusion_prepared']].fillna('').agg(\n",
    "    ' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d76c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "icpc_description_corpus = icpc_df[['cat', 'keywords']].groupby('cat').agg(' '.join).iloc[1:-1]\n",
    "icpc_description_corpus.index.name = None\n",
    "#icpc_description_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be5e86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"dataset categories: {np.array(mult_lbl_enc.classes_).astype('str')}\")\n",
    "print(f\"icpc descriptions:  {np.array(icpc_description_corpus.index).astype('str')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf707b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Integrate with CKS descriptions\n",
    "from oneinamillion.clinical_codes.cks import CksParser\n",
    "\n",
    "# use from_raw to refresh cached cks descriptions, and headings_to_include to use different set of sub-sections to include\n",
    "cks_parser = CksParser()\n",
    "cks_description_corpus = cks_parser.get_pd()\n",
    "cks_description_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7bd1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selected_mode = None\n",
    "modes = ['ICPC only', 'CKS only', 'ICPC and CKS']\n",
    "def control_description(mode=modes[0]):\n",
    "    global selected_mode\n",
    "    selected_mode = mode\n",
    "\n",
    "interact(control_description, mode=modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ecbc0",
   "metadata": {
    "pycharm": {
     "name": "#%% combine the two\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Description: {selected_mode}\")\n",
    "icpc_description_dic = {}\n",
    "for icpc_code in mult_lbl_enc.classes_:\n",
    "    icpc_code = icpc_code.upper()\n",
    "    if selected_mode == 'ICPC only':\n",
    "        icpc_description_dic[icpc_code] = f\"{icpc_description_corpus.loc[icpc_code]['keywords']}\"\n",
    "    elif selected_mode == 'CKS only':\n",
    "        icpc_description_dic[icpc_code] = f\"{cks_description_corpus.loc[icpc_code]['cks descriptions']}\"\n",
    "    else:\n",
    "        icpc_description_dic[icpc_code] = f\"{icpc_description_corpus.loc[icpc_code]['keywords']} {cks_description_corpus.loc[icpc_code]['cks descriptions']}\"\n",
    "\n",
    "icpc_corpus_df = pd.DataFrame.from_dict(icpc_description_dic, orient='index', columns=['keyword'])\n",
    "icpc_corpus = icpc_corpus_df['keyword']\n",
    "icpc_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2f127",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bag of words classifiers\n",
    "\n",
    "**Tf-idf from ICPC codes**\n",
    "\n",
    "- extract keyword/ keyphrases from ICPC code descriptions\n",
    " - use three columns (inclusion/ preferred and criteria)\n",
    "\n",
    "- OR, with TF-iDF, assign a score to every word (or bigram) in the utterance,\n",
    "filter those with only high scores\n",
    "\n",
    "- For each utterance in a transcript, count the number of keyword or phrase matches for each ICPC code.\n",
    "- If number of matches > threshold, assign ICPC code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0aaa4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from utils.stopwords import get_medical_stopwords\n",
    "# Create Bag-of-Words vector from ICPC code descriptions\n",
    "# count_vec = CountVectorizer(binary=True, ngram_range=(1, 2)) # tokenize word/ bi-gram\n",
    "\n",
    "medical_stopwords = get_medical_stopwords()\n",
    "text_vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words=medical_stopwords)\n",
    "description_vec = text_vectorizer.fit_transform(icpc_corpus)\n",
    "print(f\"icpc description bag-of-word matrix shape: {description_vec.shape}\")\n",
    "vec_vocab = text_vectorizer.vocabulary_ # dictionary that contain the BOW tokens\n",
    "\n",
    "print(f\"bag-of-word tokens: {', '.join(list(vec_vocab.keys())[:5])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910dd48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(description_vec.todense()==0, vmin=0, vmax=1, cbar=False).set_title('bag-of-words Vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218eb77a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "# test_vec = description_vec[1].todense()\n",
    "# col_names = np.array(text_vectorizer.get_feature_names())\n",
    "# test = pd.DataFrame(test_vec, columns=col_names).T.to_dict()[0]\n",
    "# print(test)\n",
    "# word_cloud = WordCloud(background_color=\"white\").generate_from_frequencies(test)\n",
    "# plt.imshow(word_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ba2e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Explain a category\n",
    "\n",
    "lookup = [x for _,x in sorted(zip(text_vectorizer.vocabulary_.values(), text_vectorizer.vocabulary_.keys()))]\n",
    "features_arr = np.array(text_vectorizer.get_feature_names())\n",
    "\n",
    "def explain_bow_vector(vec: scipy.sparse.csr.csr_matrix, ax=plt):\n",
    "    # _, idxs = scipy.sparse.csr_matrix.nonzero(vec)\n",
    "    # words = [lookup[k] for k in idxs]\n",
    "    # word_cloud = WordCloud().generate(' '.join(words))\n",
    "    test = pd.DataFrame(vec.todense(), columns=features_arr).T.to_dict()[0]\n",
    "    word_cloud = WordCloud(background_color=\"white\").generate_from_frequencies(test)\n",
    "    ax.imshow(word_cloud, interpolation='bilinear')\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "def explain_category(cat:str, ax=plt):\n",
    "    target = list(mult_lbl_enc.classes_).index(cat)\n",
    "    target = description_vec[target]\n",
    "    explain_bow_vector(target, ax=ax)\n",
    "\n",
    "def plot_explain_category(cat:str):\n",
    "    explain_category(cat)\n",
    "\n",
    "interact(plot_explain_category, cat=mult_lbl_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe627be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "key = 'transcript__conversation_both'\n",
    "# key = 'transcript__conversation_gp'\n",
    "# key = 'transcript__conversation_patient'\n",
    "\n",
    "X_train = text_vectorizer.transform(train_set[key])\n",
    "X_test = text_vectorizer.transform(test_set[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196f0e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "sns.heatmap(X_train.todense()==0, vmin=0, vmax=1, cbar=False).set_title('Train set bag-of-words matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4785ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keyword_dist_over_train = np.array(X_train.sum(axis=0)).flatten()\n",
    "\n",
    "def show_common_keywords(threshold:int = 10):\n",
    "    frequent_words = [[k,n] for k,n in zip(lookup, keyword_dist_over_train) if n > threshold]\n",
    "    frequent_words_df = pd.DataFrame(frequent_words,columns=['keyword', 'count']).sort_values('count')\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    ax = sns.barplot(x='keyword', y='count', data=frequent_words_df)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print([k._text for k in ax.get_xticklabels()])\n",
    "\n",
    "show_common_keywords()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8344d8f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Nearest Centroid classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417bc9c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kn_clf = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='cosine')\n",
    "kn_clf.fit(description_vec, mult_lbl_enc.classes_)\n",
    "\n",
    "nc_clf = NearestCentroid(metric='cosine')\n",
    "nc_clf.fit(description_vec, mult_lbl_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af2d92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mult_lbl_enc.inverse_transform(y_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807b583",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kn_clf.predict_proba(X_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c3c43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kn_y_pred = kn_clf.predict(X_train)\n",
    "y_pred = nc_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxes_with_cat(_y_train: np.ndarray, code:str):\n",
    "    y_train_raw = mult_lbl_enc.inverse_transform(_y_train)\n",
    "    return [i for i,cs in enumerate(y_train_raw) if code in cs]\n",
    "\n",
    "def get_truth_pred_pairs(_y_train, _y_pred, indices):\n",
    "    truth = mult_lbl_enc.inverse_transform(_y_train[indices])\n",
    "    pred = _y_pred[indices]\n",
    "    data = list(zip(indices, truth, pred))\n",
    "    return pd.DataFrame(data, columns=['id', 'truth', 'predicted'])\n",
    "\n",
    "def show_truth_pred_tbl(code):\n",
    "    cat_idxes = get_idxes_with_cat(y_train, code)\n",
    "    return get_truth_pred_pairs(y_train, y_pred, cat_idxes)\n",
    "\n",
    "interact(show_truth_pred_tbl, code=mult_lbl_enc.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209ba5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Seems like the baseline is not performing well on predicting classes for:\n",
    "\n",
    "A, F, N, S, T, W, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9f4eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cat_dropdown = widgets.Dropdown(options=mult_lbl_enc.classes_)\n",
    "id_dropdown = widgets.Dropdown(options=get_idxes_with_cat(y_train, cat_dropdown.value))\n",
    "\n",
    "def refresh_id_dropdown(*args):\n",
    "    id_dropdown.options = get_idxes_with_cat(y_train, cat_dropdown.value)\n",
    "\n",
    "cat_dropdown.observe(refresh_id_dropdown, 'value')\n",
    "\n",
    "def show_cosine_similarity(_id):\n",
    "    cos_sim = cosine_similarity(X_train[_id], description_vec)[0]\n",
    "    cos_sim = pd.DataFrame(list(zip(mult_lbl_enc.classes_, cos_sim)), columns=['category', 'cos sim'])\n",
    "    cos_sim = cos_sim.set_index('category').T\n",
    "    grid_kws = {\"height_ratios\": (.9, .05), \"hspace\": -0.5}\n",
    "    f, (ax, cbar_ax) = plt.subplots(2, gridspec_kw=grid_kws)\n",
    "    sns.heatmap(cos_sim, square=True, ax=ax,\n",
    "                cbar_ax=cbar_ax,\n",
    "                cbar_kws={\"orientation\": \"horizontal\"},\n",
    "                cmap='Greens')\n",
    "\n",
    "def show_keywords_true_pred(_id):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "    ax1.title.set_text('BOW from sample transcipt')\n",
    "    ax2.title.set_text('BOW of predicted class')\n",
    "    explain_bow_vector(X_train[_id], ax=ax1)\n",
    "    explain_category(y_pred[_id], ax=ax2)\n",
    "\n",
    "def view_record(_cat, _id):\n",
    "    global test\n",
    "    record = train_set.iloc[_id]\n",
    "    info = [f\"Index: {_id}\",\n",
    "           f\"Id: {record['record_id']}\",\n",
    "           f\"Actual: {mult_lbl_enc.inverse_transform(y_train[_id:_id+1])}\",\n",
    "           f\"Predicted: {y_pred[_id]}\"]\n",
    "    display(*info)\n",
    "    show_keywords_true_pred(_id)\n",
    "    show_cosine_similarity(_id)\n",
    "\n",
    "interact(view_record, _cat=cat_dropdown, _id=id_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b569de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train_mat = np.matrix(y_train)\n",
    "y_pred_mat = np.matrix(mult_lbl_enc.transform(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da71e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Note: print statements does not work in PyCharm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, multilabel_confusion_matrix, precision_recall_fscore_support, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "print(f\"classification_report:\\n{classification_report(y_train_mat, y_pred_mat, target_names=mult_lbl_enc.classes_)}\")\n",
    "\n",
    "print(f\"multilabel_confusion_matrix:\")\n",
    "conf_mat = multilabel_confusion_matrix(y_train_mat, y_pred_mat)\n",
    "\n",
    "for cls, mat in zip(mult_lbl_enc.classes_, conf_mat):\n",
    "    fig = plt.figure(figsize=(1,1))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.set_title(cls)\n",
    "    sns.heatmap(mat, ax=ax, cmap='Blues', annot=True, fmt=\"d\")\n",
    "    ax.set_xlabel('pred')\n",
    "    ax.set_ylabel('true')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90dbae6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For `average` parameter to take the average metrics over all classes, please see [documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#from-binary-to-multiclass-and-multilabel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f786764",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_result(average='weighted'):\n",
    "    # measures the subset accuracy (only considered as accurate if the whole set matches)\n",
    "    print(f\"accuracy score: {accuracy_score(y_train_mat, y_pred_mat)}\")\n",
    "\n",
    "    print(f\"f1_score: {f1_score(y_train_mat, y_pred_mat, average=average)}\")\n",
    "\n",
    "    print(f\"precision_recall_fscore_support:\\n{precision_recall_fscore_support(y_train_mat, y_pred_mat, average=average)}\")\n",
    "\n",
    "    print(f\"roc_auc_score: {roc_auc_score(y_train_mat, y_pred_mat, average=average)}\")\n",
    "\n",
    "interact(show_result, average=['macro', 'weighted', 'micro', 'samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067cca2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}