{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecac653-2d0a-4fcd-a20a-10adb23cb237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current IDs only have record documents.\n",
      "['011119' '020105' '030311' '030501' '030509' '030510' '050609' '050717'\n",
      " '050719' '071010' '071201' '071202' '071203' '071204' '071205' '071206'\n",
      " '071207' '071208' '071209' '071210' '071211' '071212' '071213' '071214'\n",
      " '081310' '081608' '081610' '091410' '091411' '091416' '101705' '101707'\n",
      " '111906' '111908' '112004' '122110']\n",
      "The current IDs only have transcript documents.\n",
      "['-081308' '010103' '010105' '020107' '030501(p.2)' '030501(p1)'\n",
      " '030509(p.1)' '030509(p.2)' '030510 (p.1)' '030510 (p.2)' '040417'\n",
      " '050605' '050609a' '050717 (Dr reads wrong number)' '060806' '060811'\n",
      " '060812' '060906' '071002' '071010(a)' '071012' '081310(b)' '081310(c)'\n",
      " '081310a' '081601' '081606' '081608 (1 of 2)' '081608 (2 of 2)' '091402'\n",
      " '091404' '091405' '091410 & 091411' '091503' '101705 and 101707' '101801'\n",
      " '111906 (2of2)' '111906(1 of 2)' '112002' '112004 & 1112005' '112014'\n",
      " '200105' '50719']\n"
     ]
    },
    {
     "data": {
      "text/plain": "   index  record_id      icpc_codes  \\\n0      0      10112  ['K85', 'P76']   \n1      1      50709  ['R04', 'U04']   \n2      2      20208         ['H82']   \n3      3      50601  ['K85', 'P15']   \n4      4     111915  ['D95', 'P74']   \n\n                                          pt_records transcript__start_date  \\\n0  [{'date': datetime.datetime(2014, 8, 13, 0, 0)...    2014-06-16 10:33:28   \n1  [{'date': datetime.datetime(2015, 1, 26, 0, 0)...    2014-11-05 19:40:49   \n2  [{'date': datetime.datetime(2014, 11, 3, 0, 0)...    2014-09-08 10:43:09   \n3  [{'date': datetime.datetime(2014, 12, 5, 0, 0)...    2014-11-05 09:27:26   \n4  [{'date': datetime.datetime(2015, 5, 29, 0, 0)...    2015-04-28 12:17:47   \n\n  transcript__duration                           transcript__conversation  \n0              0:16:17  [('GP', 'How are you sir?'), ('Patient', \"I'm ...  \n1              0:13:20  [('info', 'Oh, can I 0:00:00'), ('GP', \"___. Y...  \n2              0:11:33  [('Doc', 'Morning NAME.'), ('Pat', 'Hi, how yo...  \n3              0:19:21  [('GP', \"Thank you very much for this. Right, ...  \n4              0:19:41  [('DOC', 'Thank you, what number are you on? S...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>record_id</th>\n      <th>icpc_codes</th>\n      <th>pt_records</th>\n      <th>transcript__start_date</th>\n      <th>transcript__duration</th>\n      <th>transcript__conversation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10112</td>\n      <td>['K85', 'P76']</td>\n      <td>[{'date': datetime.datetime(2014, 8, 13, 0, 0)...</td>\n      <td>2014-06-16 10:33:28</td>\n      <td>0:16:17</td>\n      <td>[('GP', 'How are you sir?'), ('Patient', \"I'm ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>50709</td>\n      <td>['R04', 'U04']</td>\n      <td>[{'date': datetime.datetime(2015, 1, 26, 0, 0)...</td>\n      <td>2014-11-05 19:40:49</td>\n      <td>0:13:20</td>\n      <td>[('info', 'Oh, can I 0:00:00'), ('GP', \"___. Y...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20208</td>\n      <td>['H82']</td>\n      <td>[{'date': datetime.datetime(2014, 11, 3, 0, 0)...</td>\n      <td>2014-09-08 10:43:09</td>\n      <td>0:11:33</td>\n      <td>[('Doc', 'Morning NAME.'), ('Pat', 'Hi, how yo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>50601</td>\n      <td>['K85', 'P15']</td>\n      <td>[{'date': datetime.datetime(2014, 12, 5, 0, 0)...</td>\n      <td>2014-11-05 09:27:26</td>\n      <td>0:19:21</td>\n      <td>[('GP', \"Thank you very much for this. Right, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>111915</td>\n      <td>['D95', 'P74']</td>\n      <td>[{'date': datetime.datetime(2015, 5, 29, 0, 0)...</td>\n      <td>2015-04-28 12:17:47</td>\n      <td>0:19:41</td>\n      <td>[('DOC', 'Thank you, what number are you on? S...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oneinamillion.pc_consultation import PCConsultation\n",
    "\n",
    "parser = PCConsultation()  # the only class needed to obtain all PC consultation data-pairs\n",
    "orig_dataset = parser.get_pd()\n",
    "\n",
    "orig_dataset.head()  # inspect the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea4eb6-0bd9-43b8-98cc-c26caca9fa97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data preparation\n",
    "\n",
    "First split the orig_dataset into train and test set, then we need to\n",
    "pre-process the transcript data\n",
    "\n",
    "This includes, cleaning text, stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310fb443-83b6-4e2d-a5d7-79b9b8c662fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vico\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing.data import extract_icpc_categories\n",
    "from utils.transcripts import preprocess_transcripts\n",
    "\n",
    "orig_dataset['codes'] = orig_dataset['icpc_codes'].apply(extract_icpc_categories)\n",
    "orig_dataset['transcript__conversation_clean'] = orig_dataset['transcript__conversation'].apply(preprocess_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  record_id      icpc_codes  \\\n0      0      10112  ['K85', 'P76']   \n1      1      50709  ['R04', 'U04']   \n2      2      20208         ['H82']   \n3      3      50601  ['K85', 'P15']   \n4      4     111915  ['D95', 'P74']   \n\n                                          pt_records transcript__start_date  \\\n0  [{'date': datetime.datetime(2014, 8, 13, 0, 0)...    2014-06-16 10:33:28   \n1  [{'date': datetime.datetime(2015, 1, 26, 0, 0)...    2014-11-05 19:40:49   \n2  [{'date': datetime.datetime(2014, 11, 3, 0, 0)...    2014-09-08 10:43:09   \n3  [{'date': datetime.datetime(2014, 12, 5, 0, 0)...    2014-11-05 09:27:26   \n4  [{'date': datetime.datetime(2015, 5, 29, 0, 0)...    2015-04-28 12:17:47   \n\n  transcript__duration                           transcript__conversation  \\\n0              0:16:17  [('GP', 'How are you sir?'), ('Patient', \"I'm ...   \n1              0:13:20  [('info', 'Oh, can I 0:00:00'), ('GP', \"___. Y...   \n2              0:11:33  [('Doc', 'Morning NAME.'), ('Pat', 'Hi, how yo...   \n3              0:19:21  [('GP', \"Thank you very much for this. Right, ...   \n4              0:19:41  [('DOC', 'Thank you, what number are you on? S...   \n\n    codes                     transcript__conversation_clean  \n0  [K, P]  [[GP, How sir], [Patient, Im bad moment actual...  \n1  [R, U]  [[info, Oh I 00000], [GP, Youre 050709 So I gi...  \n2     [H]  [[Doc, Morning NAME], [Pat, Hi], [Doc, How], [...  \n3  [K, P]  [[GP, Thank much Right youre 050601 according]...  \n4  [D, P]  [[DOC, Thank number Sixteen Hi I Doctor Name I...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>record_id</th>\n      <th>icpc_codes</th>\n      <th>pt_records</th>\n      <th>transcript__start_date</th>\n      <th>transcript__duration</th>\n      <th>transcript__conversation</th>\n      <th>codes</th>\n      <th>transcript__conversation_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10112</td>\n      <td>['K85', 'P76']</td>\n      <td>[{'date': datetime.datetime(2014, 8, 13, 0, 0)...</td>\n      <td>2014-06-16 10:33:28</td>\n      <td>0:16:17</td>\n      <td>[('GP', 'How are you sir?'), ('Patient', \"I'm ...</td>\n      <td>[K, P]</td>\n      <td>[[GP, How sir], [Patient, Im bad moment actual...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>50709</td>\n      <td>['R04', 'U04']</td>\n      <td>[{'date': datetime.datetime(2015, 1, 26, 0, 0)...</td>\n      <td>2014-11-05 19:40:49</td>\n      <td>0:13:20</td>\n      <td>[('info', 'Oh, can I 0:00:00'), ('GP', \"___. Y...</td>\n      <td>[R, U]</td>\n      <td>[[info, Oh I 00000], [GP, Youre 050709 So I gi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20208</td>\n      <td>['H82']</td>\n      <td>[{'date': datetime.datetime(2014, 11, 3, 0, 0)...</td>\n      <td>2014-09-08 10:43:09</td>\n      <td>0:11:33</td>\n      <td>[('Doc', 'Morning NAME.'), ('Pat', 'Hi, how yo...</td>\n      <td>[H]</td>\n      <td>[[Doc, Morning NAME], [Pat, Hi], [Doc, How], [...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>50601</td>\n      <td>['K85', 'P15']</td>\n      <td>[{'date': datetime.datetime(2014, 12, 5, 0, 0)...</td>\n      <td>2014-11-05 09:27:26</td>\n      <td>0:19:21</td>\n      <td>[('GP', \"Thank you very much for this. Right, ...</td>\n      <td>[K, P]</td>\n      <td>[[GP, Thank much Right youre 050601 according]...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>111915</td>\n      <td>['D95', 'P74']</td>\n      <td>[{'date': datetime.datetime(2015, 5, 29, 0, 0)...</td>\n      <td>2015-04-28 12:17:47</td>\n      <td>0:19:41</td>\n      <td>[('DOC', 'Thank you, what number are you on? S...</td>\n      <td>[D, P]</td>\n      <td>[[DOC, Thank number Sixteen Hi I Doctor Name I...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241 entries, 0 to 240\n",
      "Data columns (total 9 columns):\n",
      " #   Column                          Non-Null Count  Dtype \n",
      "---  ------                          --------------  ----- \n",
      " 0   index                           241 non-null    int64 \n",
      " 1   record_id                       241 non-null    int64 \n",
      " 2   icpc_codes                      241 non-null    object\n",
      " 3   pt_records                      241 non-null    object\n",
      " 4   transcript__start_date          241 non-null    object\n",
      " 5   transcript__duration            241 non-null    object\n",
      " 6   transcript__conversation        241 non-null    object\n",
      " 7   codes                           241 non-null    object\n",
      " 8   transcript__conversation_clean  241 non-null    object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 17.1+ KB\n"
     ]
    }
   ],
   "source": [
    "orig_dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 classification categories: ['A' 'B' 'D' 'F' 'H' 'K' 'L' 'N' 'P' 'R' 'S' 'T' 'U' 'W' 'X' 'Y']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "y = orig_dataset['codes']\n",
    "mult_lbl_enc = MultiLabelBinarizer()\n",
    "y_hot = mult_lbl_enc.fit_transform(y)\n",
    "print(f\"{len(mult_lbl_enc.classes_)} classification categories: {mult_lbl_enc.classes_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  record_id      icpc_codes  \\\n0      0      10112  ['K85', 'P76']   \n2      2      20208         ['H82']   \n5      5     101708  ['K84', 'Y08']   \n6      6      20212  ['L10', 'R05']   \n8      8     111911  ['B80', 'D18']   \n\n                                          pt_records transcript__start_date  \\\n0  [{'date': datetime.datetime(2014, 8, 13, 0, 0)...    2014-06-16 10:33:28   \n2  [{'date': datetime.datetime(2014, 11, 3, 0, 0)...    2014-09-08 10:43:09   \n5  [{'date': datetime.datetime(2015, 4, 24, 0, 0)...    2015-02-24 12:39:49   \n6  [{'date': datetime.datetime(2014, 9, 17, 0, 0)...    2014-09-08 14:24:39   \n8  [{'date': datetime.datetime(2015, 7, 21, 0, 0)...    2015-04-28 10:48:20   \n\n  transcript__duration                           transcript__conversation  \\\n0              0:16:17  [('GP', 'How are you sir?'), ('Patient', \"I'm ...   \n2              0:11:33  [('Doc', 'Morning NAME.'), ('Pat', 'Hi, how yo...   \n5              0:18:49  [('PAT', 'He was supposed to come in and take ...   \n6              0:07:58  [('Doc', \"...you have symptoms of acid reflux,...   \n8              0:11:01  [('DOC', 'Hi, I am Doctor Name thanks for wait...   \n\n    codes                     transcript__conversation_clean  \n0  [K, P]  [[GP, How sir], [Patient, Im bad moment actual...  \n2     [H]  [[Doc, Morning NAME], [Pat, Hi], [Doc, How], [...  \n5  [K, Y]  [[PAT, He supposed come take], [info, 00001], ...  \n6  [L, R]  [[Doc, symptom acid reflux four week trial ant...  \n8  [B, D]  [[DOC, Hi I Doctor Name thanks waiting How I h...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>record_id</th>\n      <th>icpc_codes</th>\n      <th>pt_records</th>\n      <th>transcript__start_date</th>\n      <th>transcript__duration</th>\n      <th>transcript__conversation</th>\n      <th>codes</th>\n      <th>transcript__conversation_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10112</td>\n      <td>['K85', 'P76']</td>\n      <td>[{'date': datetime.datetime(2014, 8, 13, 0, 0)...</td>\n      <td>2014-06-16 10:33:28</td>\n      <td>0:16:17</td>\n      <td>[('GP', 'How are you sir?'), ('Patient', \"I'm ...</td>\n      <td>[K, P]</td>\n      <td>[[GP, How sir], [Patient, Im bad moment actual...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20208</td>\n      <td>['H82']</td>\n      <td>[{'date': datetime.datetime(2014, 11, 3, 0, 0)...</td>\n      <td>2014-09-08 10:43:09</td>\n      <td>0:11:33</td>\n      <td>[('Doc', 'Morning NAME.'), ('Pat', 'Hi, how yo...</td>\n      <td>[H]</td>\n      <td>[[Doc, Morning NAME], [Pat, Hi], [Doc, How], [...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>101708</td>\n      <td>['K84', 'Y08']</td>\n      <td>[{'date': datetime.datetime(2015, 4, 24, 0, 0)...</td>\n      <td>2015-02-24 12:39:49</td>\n      <td>0:18:49</td>\n      <td>[('PAT', 'He was supposed to come in and take ...</td>\n      <td>[K, Y]</td>\n      <td>[[PAT, He supposed come take], [info, 00001], ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>20212</td>\n      <td>['L10', 'R05']</td>\n      <td>[{'date': datetime.datetime(2014, 9, 17, 0, 0)...</td>\n      <td>2014-09-08 14:24:39</td>\n      <td>0:07:58</td>\n      <td>[('Doc', \"...you have symptoms of acid reflux,...</td>\n      <td>[L, R]</td>\n      <td>[[Doc, symptom acid reflux four week trial ant...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>111911</td>\n      <td>['B80', 'D18']</td>\n      <td>[{'date': datetime.datetime(2015, 7, 21, 0, 0)...</td>\n      <td>2015-04-28 10:48:20</td>\n      <td>0:11:01</td>\n      <td>[('DOC', 'Hi, I am Doctor Name thanks for wait...</td>\n      <td>[B, D]</td>\n      <td>[[DOC, Hi I Doctor Name thanks waiting How I h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "X = np.arange(orig_dataset['index'].shape[0]).reshape((-1, 1))\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y_hot, test_size=0.2)\n",
    "\n",
    "train_set = orig_dataset.iloc[X_train.flatten()]\n",
    "test_set = orig_dataset.iloc[X_test.flatten()]\n",
    "\n",
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "#\n",
    "# fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "# fig.suptitle('Number of records')\n",
    "# ax1.set_title('train set')\n",
    "# ax2.set_title('test set')\n",
    "#\n",
    "#\n",
    "# train_set['codes'].value_counts().sort_index().plot(kind='bar', ax=ax1)\n",
    "# test_set['codes'].value_counts().sort_index().plot(kind='bar', ax=ax2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from oneinamillion.clinical_codes.icpc import IcpcParser\n",
    "\n",
    "icpc_parser = IcpcParser()\n",
    "icpc_df = icpc_parser.get_pd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from utils.preprocessing.text import utils_preprocess_text\n",
    "\n",
    "icpc_df['cat'] = icpc_df['Code'].astype('string').apply(lambda x: x[0].lower())\n",
    "\n",
    "clean_col = lambda x: utils_preprocess_text(x) if not pd.isna(x) else x\n",
    "icpc_df['criteria_prepared'] = icpc_df['criteria'].apply(clean_col)\n",
    "icpc_df['inclusion_prepared'] = icpc_df['inclusion'].apply(clean_col)\n",
    "icpc_df['preferred_prepared'] = icpc_df['preferred'].apply(clean_col)\n",
    "icpc_df['keywords'] = icpc_df[['preferred_prepared', 'criteria_prepared', 'inclusion_prepared']].fillna('').agg(\n",
    "    ' '.join, axis=1)\n",
    "\n",
    "icpc_corpus = icpc_df[['cat', 'keywords']].groupby('cat').agg(' '.join).iloc[1:, 0]\n",
    "\n",
    "icpc_corpus = icpc_corpus.iloc[0:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset categories: ['a' 'b' 'd' 'f' 'h' 'k' 'l' 'n' 'p' 'r' 's' 't' 'u' 'w' 'x' 'y']\n",
      "icpc descriptions:  ['a' 'b' 'd' 'f' 'h' 'k' 'l' 'n' 'p' 'r' 's' 't' 'u' 'w' 'x' 'y']\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset categories: {np.array([x for x in icpc_corpus.index if x.upper() in mult_lbl_enc.classes_]).astype('str')}\")\n",
    "print(f\"icpc descriptions:  {np.array(icpc_corpus.index).astype('str')}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline - Tf-idf from ICPC codes\n",
    "\n",
    "- extract keyword/ keyphrases from ICPC code descriptions\n",
    " - use three columns (inclusion/ preferred and criteria)\n",
    "\n",
    "- OR, with TF-iDF, assign a score to every word (or bigram) in the utterance,\n",
    "filter those with only high scores\n",
    "\n",
    "- For each utterance in a transcript, count the number of keyword or phrase matches for each ICPC code.\n",
    "- If number of matches > threshold, assign ICPC code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, a CountVectoriser is used to tokenize the ICPC code descriptions, and to create bag-of-word vectors\n",
    "for every ICPC categories. The vector indicates the presence of word/ bi-gram in each ICPC code description"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag-of-word tokens: pain, general, multiple, site, chronic...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create Bag-of-Words vector from ICPC code descriptions\n",
    "count_vec = CountVectorizer(binary=True, ngram_range=(1, 2)) # tokenize word/ bi-gram\n",
    "icpc_count_vec = count_vec.fit_transform(icpc_corpus)\n",
    "vec_vocab = count_vec.vocabulary_ # dictionary that contain the BOW tokens\n",
    "\n",
    "print(f\"bag-of-word tokens: {', '.join(list(vec_vocab.keys())[:5])}...\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This KDTree stores N-dimensional bag-of-words vector for all ICPC categories, and allow quick closest neighbour lookup\n",
    "using any bag-of-words vector from transcripts."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "lookup_tree = KDTree(icpc_count_vec.todense())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from skmultilearn.base import MLClassifierBase\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class KDTreeMLClassifier(BaseEstimator):\n",
    "    def __init__(self, feature_vec=None, k=5, distance_upper_bound=50, p_threshold=0.2):\n",
    "        self._tree = KDTree(feature_vec)\n",
    "        self.k = k\n",
    "        self.distance_upper_bound = distance_upper_bound\n",
    "        self.p_threshold = p_threshold\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "        pass\n",
    "\n",
    "    def _bow_vec_2_cat(self, vec):\n",
    "        \"\"\"\n",
    "        :param vec: bag-of-word vector from a transcript\n",
    "        :return: probability vector of length class\n",
    "        \"\"\"\n",
    "        ds, cs = lookup_tree.query(vec, k=5, distance_upper_bound=self.distance_upper_bound)\n",
    "        ds = np.array([d for (d,c) in zip(ds, cs) if not np.isinf(d)])\n",
    "        cs = np.array([c for (d,c) in zip(ds, cs) if not np.isinf(d)])\n",
    "\n",
    "        ds = (self.distance_upper_bound/ds)  # set distance to class as probability of being that class\n",
    "        ds = ds/ds.sum()  # normalize to sum up to 1\n",
    "        # create an output vector of class probabilities\n",
    "        x = np.zeros(len(self._tree.data))\n",
    "        for d,c in zip(ds, cs):\n",
    "            x[c] = d\n",
    "        x = np.where(x >= self.p_threshold, 1, 0)\n",
    "        return x\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make class predictions for n samples give (n,m) matrix\n",
    "        :param X: bag-of-word matrix (n,m) for n samples and m features\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return np.apply_along_axis(self._bow_vec_2_cat, axis=1, arr=X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from utils.transcripts import apply_to_transcript\n",
    "\n",
    "def logic_or_seq(xs: Union[List[int], List[bool]]) -> Union[int, bool]:\n",
    "    \"\"\"Return the reduced OR value of a sequence of boolean values\n",
    "    [1,0] -> 1\n",
    "    [True, False] -> True\n",
    "    \"\"\"\n",
    "    res = reduce((lambda a, b: a or b), xs, False)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def transcript_to_bow_vec(_dialogue, _vectorizer):\n",
    "    \"\"\"Convert transcript to bag-of-word vector\"\"\"\n",
    "    [_, transcript_mat] = apply_to_transcript(_dialogue, fn_utterance=_vectorizer.transform, merge=True)\n",
    "    return np.apply_along_axis(logic_or_seq, 0, np.array(transcript_mat.todense()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# # Get bag-of-words count vector on a single transcript\n",
    "#\n",
    "# idx = 7  # idx of train set\n",
    "#\n",
    "# dialogue = train_set.iloc[idx]['transcript__conversation_clean']\n",
    "#\n",
    "# transcript_vec = transcript_to_bow_vec(dialogue, count_vec)\n",
    "# print(transcript_vec)\n",
    "# print(f\"shape: {transcript_vec.shape}\")\n",
    "# print(f\"contain 1s?: {not np.all(transcript_vec == 0)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Now apply the bag-of-word transformation to all samples in train set\n",
    "transcript_bow_vecs = train_set['transcript__conversation_clean'].apply(lambda x: transcript_to_bow_vec(x, count_vec))\n",
    "X_train = np.stack(transcript_bow_vecs)  # np 2d array for bag-of-word vectors for all train samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# def bow_vec_2_cat(vec):\n",
    "#     distance_upper_bound = 50\n",
    "#     ds, cs = lookup_tree.query(vec, k=5, distance_upper_bound=distance_upper_bound)\n",
    "#     ds = np.array([d for (d,c) in zip(ds, cs) if not np.isinf(d)])\n",
    "#     cs = np.array([c for (d,c) in zip(ds, cs) if not np.isinf(d)])\n",
    "#\n",
    "#     ds = (distance_upper_bound/ds)\n",
    "#     ds = ds/ds.sum()\n",
    "#\n",
    "#\n",
    "#     x = np.zeros(17)\n",
    "#     for d,c in zip(ds, cs):\n",
    "#         x[c] = d\n",
    "#\n",
    "#     return x\n",
    "#\n",
    "# xx = bow_vec_2_cat(transcript_bow_vecs.iloc[idx])\n",
    "# print(f\"predictions: {xx}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "mlc = KDTreeMLClassifier(feature_vec=icpc_count_vec.todense())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "y_pred = mlc.predict(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: (187, 16)\n",
      "y_pred:  (187, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_pred:  {y_pred.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.043760199405360696\n",
      "accuracy: 0.016042780748663103\n"
     ]
    }
   ],
   "source": [
    "# Test the performance of the classifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "print(f\"f1: {f1_score(y_train, y_pred, average='weighted')}\")\n",
    "print(f\"accuracy: {accuracy_score(y_train, y_pred)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "data must be 2 dimensions",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-24-23c0b73400b2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m ]\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mmlc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mKDTreeMLClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[0mgrid_search\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmlc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-14-a4a57984fb63>\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, feature_vec, k, distance_upper_bound, p_threshold)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mKDTreeMLClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseEstimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeature_vec\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdistance_upper_bound\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp_threshold\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tree\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mKDTree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeature_vec\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mk\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdistance_upper_bound\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdistance_upper_bound\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NLP_GP\\lib\\site-packages\\scipy\\spatial\\kdtree.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, leafsize, compact_nodes, copy_data, balanced_tree, boxsize)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    336\u001B[0m         \u001B[1;31m# Note KDTree has different default leafsize from cKDTree\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 337\u001B[1;33m         super().__init__(data, leafsize, compact_nodes, copy_data,\n\u001B[0m\u001B[0;32m    338\u001B[0m                          balanced_tree, boxsize)\n\u001B[0;32m    339\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mckdtree.pyx\u001B[0m in \u001B[0;36mscipy.spatial.ckdtree.cKDTree.__init__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: data must be 2 dimensions"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'k':5,\n",
    "        'distance_upper_bound': np.linspace(10, 50, 6),\n",
    "        'p_threshold': np.linspace(0.1, 0.5, 6),\n",
    "    }\n",
    "]\n",
    "\n",
    "mlc = KDTreeMLClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(mlc, )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}