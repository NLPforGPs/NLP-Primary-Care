{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecac653-2d0a-4fcd-a20a-10adb23cb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from oneinamillion.pc_consultation import PCConsultation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e09ab-d450-4d5c-8323-0f566e3856ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = PCConsultation()\n",
    "\n",
    "orig_dataset = parser.get_pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea4eb6-0bd9-43b8-98cc-c26caca9fa97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data preparation\n",
    "\n",
    "First split the orig_dataset into train and test set, then we need to\n",
    "pre-process the transcript data\n",
    "\n",
    "This includes, cleaning text, stemming and lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebd565-9874-4be0-ad07-95cc6545e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fb443-83b6-4e2d-a5d7-79b9b8c662fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing.data import extract_icpc_categories\n",
    "from preprocessing.text import preprocess_transcripts\n",
    "\n",
    "orig_dataset['codes'] = orig_dataset['icpc_codes'].apply(extract_icpc_categories)\n",
    "orig_dataset['transcript__conversation_clean'] = orig_dataset['transcript__conversation'].apply(preprocess_transcripts)\n",
    "\n",
    "# dataset = orig_dataset.explode(column='codes')\n",
    "# dataset['codes'] = dataset['codes'].astype('category')\n",
    "\n",
    "orig_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "orig_dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = orig_dataset['codes']\n",
    "\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mult_lbl_enc = MultiLabelBinarizer()\n",
    "y_hot = mult_lbl_enc.fit_transform(y)\n",
    "print(mult_lbl_enc.classes_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.arange(orig_dataset['index'].shape[0]).reshape((-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y_hot, test_size=0.2)\n",
    "\n",
    "train_set = orig_dataset.iloc[X_train.flatten()]\n",
    "test_set = orig_dataset.iloc[X_test.flatten()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#\n",
    "# split = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\n",
    "# splits = split.split(dataset, dataset['codes'])\n",
    "#\n",
    "# for train_index, test_index in splits:\n",
    "#     train_set = dataset.iloc[train_index]\n",
    "#     test_set = dataset.iloc[test_index]\n",
    "\n",
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "#\n",
    "# fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "# fig.suptitle('Number of records')\n",
    "# ax1.set_title('train set')\n",
    "# ax2.set_title('test set')\n",
    "#\n",
    "#\n",
    "# train_set['codes'].value_counts().sort_index().plot(kind='bar', ax=ax1)\n",
    "# test_set['codes'].value_counts().sort_index().plot(kind='bar', ax=ax2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "# \n",
    "# pd.DataFrame({\n",
    "#     'train': Counter(str(combination) for row in get_combination_wise_output_matrix(y_train, order=3) for combination in row),\n",
    "#     'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(y_test, order=3) for combination in row)\n",
    "# }).T.fillna(0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from oneinamillion.clinical_codes.icpc import IcpcParser\n",
    "\n",
    "icpc_parser = IcpcParser()\n",
    "\n",
    "icpc_df = icpc_parser.get_pd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from preprocessing.text import utils_preprocess_text\n",
    "\n",
    "icpc_df['cat'] = icpc_df['Code'].astype('string').apply(lambda x: x[0].lower())\n",
    "\n",
    "clean_col = lambda x: utils_preprocess_text(x) if not pd.isna(x) else x\n",
    "icpc_df['criteria_prepared'] = icpc_df['criteria'].apply(clean_col)\n",
    "icpc_df['inclusion_prepared'] = icpc_df['inclusion'].apply(clean_col)\n",
    "icpc_df['preferred_prepared'] = icpc_df['preferred'].apply(clean_col)\n",
    "\n",
    "icpc_df['keywords'] = icpc_df[['preferred_prepared', 'criteria_prepared', 'inclusion_prepared']].fillna('').agg(\n",
    "    ' '.join, axis=1)\n",
    "\n",
    "icpc_keywords_df = icpc_df[['cat', 'keywords']].groupby('cat').agg(' '.join)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "icpc_corpus = icpc_keywords_df.iloc[1:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline - Tf-idf from ICPC codes\n",
    "\n",
    "- extract keyword/ keyphrases from ICPC code descriptions\n",
    " - use three columns (inclusion/ preferred and criteria)\n",
    "\n",
    "- OR, with TF-iDF, assign a score to every word (or bigram) in the utterance,\n",
    "filter those with only high scores\n",
    "\n",
    "- For each utterance in a transcript, count the number of keyword or phrase matches for each ICPC code.\n",
    "- If number of matches > threshold, assign ICPC code\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectoriser = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "icpc_vec = vectoriser.fit_transform(icpc_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "dic_vocab = vectoriser.vocabulary_\n",
    "\n",
    "sns.heatmap(icpc_vec.todense()[:, np.random.randint(0, icpc_vec.shape[1], 100)] == 0, vmin=0, vmax=1,\n",
    "            cbar=False).set_title('Sparse Matrix Sample')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dic_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = train_set[['record_id', 'transcript__conversation_clean', 'codes']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def apply_to_transcript(transcript: List[List[str]], fn_speaker=None, fn_utterance=None, merge=False):\n",
    "    new_transcript = []\n",
    "    if not merge:\n",
    "        for speaker, utterance in transcript:\n",
    "            current = [speaker, utterance]\n",
    "            if fn_speaker is not None:\n",
    "                current[0] = fn_speaker(speaker)\n",
    "            if fn_utterance is not None:\n",
    "                current[1] = fn_utterance(utterance)\n",
    "            new_transcript.append(current)\n",
    "        return new_transcript\n",
    "    else:\n",
    "        speaker = [x[0] for x in transcript]\n",
    "        utterance = [x[1] for x in transcript]\n",
    "        if fn_speaker is not None:\n",
    "            speaker = fn_speaker(speaker)\n",
    "        if fn_utterance is not None:\n",
    "            utterance = fn_utterance(utterance)\n",
    "        return speaker, utterance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "dialogue = test_df.iloc[idx]['transcript__conversation_clean']\n",
    "\n",
    "test = apply_to_transcript(dialogue, fn_utterance=vectoriser.transform, merge=True)\n",
    "\n",
    "matrix = test[1]\n",
    "\n",
    "sns.heatmap(matrix.todense()[:, np.random.randint(0, matrix.shape[1], 100)] == 0, vmin=0, vmax=1,\n",
    "            cbar=False).set_title(f'keyword occ in utterances for {test_df.iloc[idx][\"record_id\"]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_mat = np.array(matrix.todense())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inv_dic_vocab = {v: k for k, v in dic_vocab.items()}\n",
    "inv_dic_vocab[5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}